//
// Generated by LLVM NVPTX Back-End
//

.version 7.2
.target sm_80
.address_size 64

	// .weak	_ZTSZZ4mainENKUlRN2cl4sycl7handlerEE_clES2_E7imatrix

.weak .entry _ZTSZZ4mainENKUlRN2cl4sycl7handlerEE_clES2_E7imatrix(
	.param .u64 _ZTSZZ4mainENKUlRN2cl4sycl7handlerEE_clES2_E7imatrix_param_0,
	.param .align 8 .b8 _ZTSZZ4mainENKUlRN2cl4sycl7handlerEE_clES2_E7imatrix_param_1[8],
	.param .align 8 .b8 _ZTSZZ4mainENKUlRN2cl4sycl7handlerEE_clES2_E7imatrix_param_2[8],
	.param .align 8 .b8 _ZTSZZ4mainENKUlRN2cl4sycl7handlerEE_clES2_E7imatrix_param_3[8],
	.param .u64 _ZTSZZ4mainENKUlRN2cl4sycl7handlerEE_clES2_E7imatrix_param_4,
	.param .align 8 .b8 _ZTSZZ4mainENKUlRN2cl4sycl7handlerEE_clES2_E7imatrix_param_5[8],
	.param .align 8 .b8 _ZTSZZ4mainENKUlRN2cl4sycl7handlerEE_clES2_E7imatrix_param_6[8],
	.param .align 8 .b8 _ZTSZZ4mainENKUlRN2cl4sycl7handlerEE_clES2_E7imatrix_param_7[8],
	.param .u64 _ZTSZZ4mainENKUlRN2cl4sycl7handlerEE_clES2_E7imatrix_param_8,
	.param .align 8 .b8 _ZTSZZ4mainENKUlRN2cl4sycl7handlerEE_clES2_E7imatrix_param_9[8],
	.param .align 8 .b8 _ZTSZZ4mainENKUlRN2cl4sycl7handlerEE_clES2_E7imatrix_param_10[8],
	.param .align 8 .b8 _ZTSZZ4mainENKUlRN2cl4sycl7handlerEE_clES2_E7imatrix_param_11[8],
	.param .u64 _ZTSZZ4mainENKUlRN2cl4sycl7handlerEE_clES2_E7imatrix_param_12,
	.param .align 8 .b8 _ZTSZZ4mainENKUlRN2cl4sycl7handlerEE_clES2_E7imatrix_param_13[8],
	.param .align 8 .b8 _ZTSZZ4mainENKUlRN2cl4sycl7handlerEE_clES2_E7imatrix_param_14[8],
	.param .align 8 .b8 _ZTSZZ4mainENKUlRN2cl4sycl7handlerEE_clES2_E7imatrix_param_15[8]
)
{
	.reg .b32 	%r<25>;
	.reg .b64 	%rd<25>;

	ld.param.u64 	%rd1, [_ZTSZZ4mainENKUlRN2cl4sycl7handlerEE_clES2_E7imatrix_param_0];
	ld.param.u64 	%rd2, [_ZTSZZ4mainENKUlRN2cl4sycl7handlerEE_clES2_E7imatrix_param_4];
	ld.param.u64 	%rd3, [_ZTSZZ4mainENKUlRN2cl4sycl7handlerEE_clES2_E7imatrix_param_3];
	ld.param.u64 	%rd4, [_ZTSZZ4mainENKUlRN2cl4sycl7handlerEE_clES2_E7imatrix_param_8];
	ld.param.u64 	%rd5, [_ZTSZZ4mainENKUlRN2cl4sycl7handlerEE_clES2_E7imatrix_param_7];
	ld.param.u64 	%rd6, [_ZTSZZ4mainENKUlRN2cl4sycl7handlerEE_clES2_E7imatrix_param_11];
	ld.param.u64 	%rd7, [_ZTSZZ4mainENKUlRN2cl4sycl7handlerEE_clES2_E7imatrix_param_12];
	ld.param.u64 	%rd8, [_ZTSZZ4mainENKUlRN2cl4sycl7handlerEE_clES2_E7imatrix_param_15];
	mov.u32 	%r1, %ctaid.y;
	mov.u32 	%r2, %ctaid.x;
	shl.b32 	%r3, %r1, 8;
	cvt.u64.u32 	%rd9, %r3;
	mul.wide.u32 	%rd10, %r2, 16;
	add.s64 	%rd11, %rd10, %rd9;
	add.s64 	%rd12, %rd11, %rd3;
	shl.b64 	%rd13, %rd12, 2;
	add.s64 	%rd14, %rd1, %rd13;
	mov.u32 	%r4, 16;
	wmma.load.c.sync.aligned.row.m16n16k16.global.s32 	{%r5, %r6, %r7, %r8, %r9, %r10, %r11, %r12}, [%rd14], %r4;
	add.s64 	%rd15, %rd10, %rd5;
	shl.b64 	%rd16, %rd15, 2;
	add.s64 	%rd17, %rd2, %rd16;
	wmma.load.a.sync.aligned.row.m16n16k16.global.s8 	{%r13, %r14}, [%rd17], %r4;
	add.s64 	%rd18, %rd6, %rd9;
	shl.b64 	%rd19, %rd18, 2;
	add.s64 	%rd20, %rd4, %rd19;
	wmma.load.b.sync.aligned.col.m16n16k16.global.s8 	{%r15, %r16}, [%rd20], %r4;
	wmma.mma.sync.aligned.row.col.m16n16k16.s32.s8.s8.s32
		{%r17, %r18, %r19, %r20, %r21, %r22, %r23, %r24},
		{%r13, %r14},
		{%r15, %r16},
		{%r5, %r6, %r7, %r8, %r9, %r10, %r11, %r12};
	add.s64 	%rd21, %rd11, %rd8;
	shl.b64 	%rd22, %rd21, 2;
	add.s64 	%rd23, %rd7, %rd22;
	cvta.global.u64 	%rd24, %rd23;
	wmma.store.d.sync.aligned.row.m16n16k16.s32 	[%rd24],{%r17, %r18, %r19, %r20, %r21, %r22, %r23, %r24}, %r4;
	ret;

}
